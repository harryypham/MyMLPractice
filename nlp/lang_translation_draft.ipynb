{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harryypham/MyMLPractice/blob/main/nlp/lang_translation_draft.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "JQaSKo3sS7Ix"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "s4TieDQMT5uC"
      },
      "outputs": [],
      "source": [
        "data_path = 'data'\n",
        "src_lang = 'en'\n",
        "tgt_lang = 'vi'\n",
        "\n",
        "def load_data(data_path, split):\n",
        "  data_path = os.path.join(data_path, split)\n",
        "  with open(os.path.join(data_path, src_lang + '.txt'), 'r', encoding='utf-8') as src_f:\n",
        "    src_data = src_f.read()\n",
        "\n",
        "  with open(os.path.join(data_path, tgt_lang + '.txt'), 'r', encoding='utf-8') as tgt_f:\n",
        "    tgt_data = tgt_f.read()\n",
        "\n",
        "  return src_data, tgt_data\n",
        "\n",
        "def load_dataset(src_data, tgt_data, src_encode, tgt_encode, tokenizer):\n",
        "  data = []\n",
        "  for i, (src, tgt) in enumerate(zip(src_data.split('\\n'), tgt_data.split('\\n'))):\n",
        "    src_toks, tgt_toks = tokenizer(src), tokenizer(tgt)\n",
        "    src_ids, tgt_ids = src_encode(src_toks), tgt_encode(tgt_toks)\n",
        "    data.append([src_ids, tgt_ids])\n",
        "  return data\n",
        "\n",
        "def tokenizer(s):\n",
        "  return ['<bos>'] + s.split(' ') + ['<eos>']\n",
        "\n",
        "def build_vocab(data, min_freq=2):\n",
        "  word_freq = Counter()\n",
        "  data = \" \".join(data.split('\\n'))\n",
        "  word_freq.update(data.split(' '))\n",
        "  vocab = [w for w in word_freq.keys() if word_freq[w] >= min_freq]\n",
        "  return vocab\n",
        "\n",
        "def build_tokenizer(vocab):\n",
        "  stoi = {s:i+4 for i,s in enumerate(vocab)}\n",
        "  stoi['<unk>'] = 0\n",
        "  stoi['<bos>'] = 1\n",
        "  stoi['<eos>'] = 2\n",
        "  stoi['<pad>'] = 3\n",
        "  itos = {i:s for s,i in stoi.items()}\n",
        "  encode = lambda s: [stoi.get(w, stoi['<unk>']) for w in s]\n",
        "  decode = lambda l: ' '.join([itos[i] for i in l if i != 3])\n",
        "  return encode, decode\n",
        "\n",
        "def get_batch(data, batch_size):\n",
        "  ix = torch.randint(len(data), (batch_size,))\n",
        "  src_max_len = max([len(data[i][0]) for i in ix])\n",
        "  tgt_max_len = max([len(data[i][1]) for i in ix])\n",
        "  x = torch.stack([torch.tensor(data[i][0] + [3] * (src_max_len - len(data[i][0])), dtype=torch.long) for i in ix])\n",
        "  y = torch.stack([torch.tensor(data[i][1] + [3] * (tgt_max_len - len(data[i][1])), dtype=torch.long)  for i in ix])\n",
        "  return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNkicto7U3LB",
        "outputId": "47feabf1-d735-419a-9d69-26a80fe25505"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32258 14318\n",
            "tensor([[    1,  3627,  2260,     7,  4827,    29,   516, 12885,  1393,    47,\n",
            "          1736, 13221,    13, 21634, 21635,   600,     7,  8084,    57,   621,\n",
            "           441,    51,   662,  3976,  5481,    70,  5160,  7780,    51,  3607,\n",
            "           122,  5436,   150,   370, 21636,    13, 21637, 21638,    70,  4777,\n",
            "          1662,    20, 21639, 21640,    47,     2,     3],\n",
            "        [    1,     4, 22612, 10838,   127,   647,   983,   138,   200,  4087,\n",
            "            20, 14232,    13,   212,   460,    48,   133,   329,  2492,    13,\n",
            "           478,   173,   380,    53,     7,   692,  1862,    20,     7, 30498,\n",
            "            47,     2,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3],\n",
            "        [    1,   110,   516,    33,   214,  1280,   387,  4406,   166, 15946,\n",
            "           113,    13,   211,    13,   138,  2379,  1893,    13,    21,   130,\n",
            "           670,  3853,  5352,   149,    47,     2,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3],\n",
            "        [    1,   289,   183,    13,   138,   507,    13,   174,   378,   124,\n",
            "          3313,     0, 11479,    13,  2265,   234,   782,   337,   491,  2745,\n",
            "            13,    51,   380, 25367,    70,   946,   162,    21,  6838,   130,\n",
            "           127,    50,   138,    57,   532,    13,   212,    67,   319, 11047,\n",
            "            29,   948,    70,  1837,   948,    47,     2]]) tensor([[    1,  1049,   485,   486,   199,     8,  1567,  2507,   629,   101,\n",
            "           307,  2944,   160,   195,  1576,    72,  1466,  6116,    17,  9331,\n",
            "          9332,   212,   630,    39,   169,   482,     8,   362,   450,   451,\n",
            "           501,    63,  2189,    64,    28,   535,   400,    87,    97,   450,\n",
            "           451,  2240,   290,  1074,    63,   380,   337,    28,   634,   579,\n",
            "            93,  1422,  1088,   443,    17,  2011,  4135,    69,   767,    17,\n",
            "            97,   222,   579,  3032,  2693,   142,    72,     2],\n",
            "        [    1,  4332,  1539,  9726,   134,    77,   160,   187,   176,   136,\n",
            "           444,  2475,   585,    75,  2547,    17,   355,   330,   708,    95,\n",
            "           170,   723,   615,    98,   333,   178,   574,    63,   170,    24,\n",
            "            25,    39,    75,    76,     8,   350,   625,   434,   125,   305,\n",
            "             2,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    1,   502,   956,   162,    78,    77,   164,   282,   892,    55,\n",
            "          1646,   248,    94,   265,    17,   136,    17,   259,   693,   355,\n",
            "           265,   330,    17,    82,    80,   681,    66,    94,    24,  1832,\n",
            "          2035,    39,   260,    72,     2,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    1,  2637,   559,    93,   272,   116,    17,   169,   170,   450,\n",
            "           451,    82,  1183, 12841,  8453,    63,    52,    48,  1670,  1671,\n",
            "            97,   658,   545,    88,   134,    94,    24,   347,   546,   881,\n",
            "            43,    48,   330,    63,   130,   199,   220,   315,    97,   408,\n",
            "          1577,    72,     2,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3]])\n"
          ]
        }
      ],
      "source": [
        "data = load_data(data_path, 'train')\n",
        "src_vocab = build_vocab(data[0])\n",
        "tgt_vocab = build_vocab(data[1])\n",
        "src_vocab_size = len(src_vocab)\n",
        "tgt_vocab_size = len(tgt_vocab)\n",
        "print(src_vocab_size, tgt_vocab_size)\n",
        "src_encode, src_decode = build_tokenizer(src_vocab)\n",
        "tgt_encode, tgt_decode = build_tokenizer(tgt_vocab)\n",
        "train_data = load_dataset(data[0], data[1], src_encode, tgt_encode, tokenizer)\n",
        "xb, yb = get_batch(train_data, 4)\n",
        "print(xb, yb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "pKhGuya4m134",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62a6c93b-df2e-48b2-b6d4-4967f5b93eaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bos> In fact , right now -- plug it from here , and then plug it in here , and now let &apos;s see if it gets my facial expressions . <eos>\n"
          ]
        }
      ],
      "source": [
        "print(src_decode(xb[0].tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "  def __init__(self, hidden_size, emb_dim, num_layers, vocab_size, encoder=True):\n",
        "    super().__init__()\n",
        "    self.embedding_table = nn.Embedding(vocab_size, emb_dim)\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    self.lstm = nn.LSTM(emb_dim, hidden_size, num_layers, batch_first=True)\n",
        "    if encoder:\n",
        "      self.fc = nn.Linear(hidden_size, hidden_size)\n",
        "    else:\n",
        "      self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "  def forward(self, x, targets=None):\n",
        "    h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "    c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "\n",
        "    x = self.embedding_table(x)\n",
        "    logits, _ = self.lstm(x, (h0, c0))\n",
        "    if targets is not None:\n",
        "      B, T, C = logits.shape\n",
        "      logits = self.fc(logits.reshape(B*T, C))\n",
        "      targets = targets.view(-1)\n",
        "      loss = F.cross_entropy(logits, targets)\n",
        "    else:\n",
        "      logits = self.fc(logits[:, -1, :])\n",
        "      loss = None\n",
        "    return logits, loss\n"
      ],
      "metadata": {
        "id": "DLtO-VNmvb5S"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = LSTM(256, 64, 2, src_vocab_size)\n",
        "logits, loss = encoder(xb)\n",
        "print(logits.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtvDos6Gww66",
        "outputId": "6da09e8e-2b55-4267-ae97-ad4eafd985af"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 256])\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMDAteXKLymFeeA/FvaZFYs",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}