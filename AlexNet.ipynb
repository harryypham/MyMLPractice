{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOQFF/dl3BAcMQ3f4slHh7/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harryypham/MyMLPractice/blob/main/AlexNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yYa6ZaOEkgsg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils as utils\n",
        "import torch.optim as optim\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((70, 70)),\n",
        "    transforms.RandomCrop((64, 64)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root=\"/content/data/train\", train=True, download=True, transform=train_transform)\n",
        "validset = torchvision.datasets.CIFAR10(root=\"/content/data/train\", train=True, transform=test_transform)\n",
        "testset = torchvision.datasets.CIFAR10(root=\"/content/data/test\", train=False, download=True, transform=test_transform)\n",
        "\n",
        "def split_train_valid(valid_size=0.1):\n",
        "  train_indices = torch.arange(0, int(50000*(1-valid_size)))\n",
        "  valid_indices = torch.arange(int(50000*(1-valid_size)), 50000)\n",
        "\n",
        "  train_sampler = utils.data.SubsetRandomSampler(train_indices)\n",
        "  valid_sampler = utils.data.SubsetRandomSampler(valid_indices)\n",
        "\n",
        "  return train_sampler, valid_sampler\n"
      ],
      "metadata": {
        "id": "ef6rN45WmjNW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31c40761-3ff8-42f2-e576-316fcc5c0f6c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /content/data/train/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:13<00:00, 12788243.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/data/train/cifar-10-python.tar.gz to /content/data/train\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /content/data/test/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:12<00:00, 13123236.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/data/test/cifar-10-python.tar.gz to /content/data/test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "batch_size = 128\n",
        "epochs = 20"
      ],
      "metadata": {
        "id": "fb9sOi8ST--9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sampler, valid_sampler = split_train_valid()\n",
        "trainloader = utils.data.DataLoader(trainset, batch_size=batch_size, sampler=train_sampler, num_workers=2)\n",
        "validloader = utils.data.DataLoader(trainset, batch_size=batch_size, sampler=valid_sampler, num_workers=2)\n",
        "testloader = utils.data.DataLoader(testset, batch_size=batch_size, num_workers=2)"
      ],
      "metadata": {
        "id": "cczV0vVIUDNh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking dimension\n",
        "for images, labels in trainloader:\n",
        "    print('Image batch dimensions:', images.size())\n",
        "    print('Image label dimensions:', labels.size())\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gMg7TGQtEhG",
        "outputId": "0efc4b81-9640-44d1-acc2-b2df7f3de087"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image batch dimensions: torch.Size([128, 3, 64, 64])\n",
            "Image label dimensions: torch.Size([128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AlexNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        #Conv1\n",
        "        nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        nn.LocalResponseNorm(size=5, alpha=1e-4, beta=0.75, k=2),\n",
        "\n",
        "        #Conv2\n",
        "        nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        nn.LocalResponseNorm(size=5, alpha=1e-4, beta=0.75, k=2),\n",
        "\n",
        "        #Conv3\n",
        "        nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        #Conv4\n",
        "        nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        #Conv5\n",
        "        nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "    )\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "\n",
        "    self.fc = nn.Sequential(\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(256 * 6 * 6, 4096),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(4096, 4096),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(4096, 10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    x = self.avgpool(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.fc(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "SE-WgcpwtGBc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_accuracy(model, dataloader, device):\n",
        "    \"\"\"\n",
        "    Compute accuracy on dataset\n",
        "    \"\"\"\n",
        "    correct, total = 0, 0\n",
        "    model.to(device)\n",
        "    for inputs, targets in dataloader:\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predict = outputs.max(1)\n",
        "\n",
        "        total += targets.size(0)\n",
        "        correct += predict.eq(targets).sum().item()\n",
        "\n",
        "    return correct/total * 100\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "24wYCD2CzHER"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, trainloader, validloader, criterion, optimizer, epochs, device, compute_accuracy):\n",
        "  loss_history, acc_history = [], []\n",
        "  for epoch in range(epochs):\n",
        "    print(f'\\nEpoch {epoch+1}:')\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        model.train()\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predict = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predict.eq(targets).sum().item()\n",
        "\n",
        "        if (not batch_idx % 50) and batch_idx != 0:\n",
        "              print ('Batch %03d | Cost: %.6f | Train Acc: %.4f'\n",
        "                    %(batch_idx, train_loss/(batch_idx+1), 100*correct/total))\n",
        "\n",
        "    loss_history.append(train_loss/(batch_idx+1))\n",
        "    acc_history.append(100*correct/total)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.set_grad_enabled(False):\n",
        "        valid_acc = compute_accuracy(model, validloader, device)\n",
        "    print ('Valid Acc: %.4f' % (valid_acc))\n",
        "\n",
        "  return loss_history, acc_history\n",
        "\n",
        "\n",
        "\n",
        "def test(model, testloader, device, compute_accuracy):\n",
        "  model.eval()\n",
        "  with torch.set_grad_enabled(False):\n",
        "    test_acc = compute_accuracy(model, testloader, device)\n",
        "  return test_acc"
      ],
      "metadata": {
        "id": "kl5fHs3fzDyH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AlexNet()\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=5e-4)\n",
        "loss_history, acc_history = train(model, trainloader, validloader, criterion, optimizer, epochs, device, compute_accuracy)\n",
        "test_acc = test(model, testloader, device, compute_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6w467e_nyKQG",
        "outputId": "fe1599cf-fa9e-4f06-bc19-e5538f43a46e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1:\n",
            "Batch 050 | Cost: 2.184216 | Train Acc: 14.1697\n",
            "Batch 100 | Cost: 2.069616 | Train Acc: 18.3323\n",
            "Batch 150 | Cost: 1.992834 | Train Acc: 20.6902\n",
            "Batch 200 | Cost: 1.933537 | Train Acc: 22.8273\n",
            "Batch 250 | Cost: 1.890591 | Train Acc: 24.6514\n",
            "Batch 300 | Cost: 1.845879 | Train Acc: 26.6715\n",
            "Batch 350 | Cost: 1.807046 | Train Acc: 28.4477\n",
            "Valid Acc: 41.6200\n",
            "\n",
            "Epoch 2:\n",
            "Batch 050 | Cost: 1.489876 | Train Acc: 42.8309\n",
            "Batch 100 | Cost: 1.478596 | Train Acc: 43.4638\n",
            "Batch 150 | Cost: 1.458008 | Train Acc: 44.2674\n",
            "Batch 200 | Cost: 1.441386 | Train Acc: 45.0715\n",
            "Batch 250 | Cost: 1.426502 | Train Acc: 45.8759\n",
            "Batch 300 | Cost: 1.413750 | Train Acc: 46.5142\n",
            "Batch 350 | Cost: 1.398844 | Train Acc: 47.2801\n",
            "Valid Acc: 52.4400\n",
            "\n",
            "Epoch 3:\n",
            "Batch 050 | Cost: 1.284678 | Train Acc: 52.6961\n",
            "Batch 100 | Cost: 1.265424 | Train Acc: 53.4808\n",
            "Batch 150 | Cost: 1.252867 | Train Acc: 53.9839\n",
            "Batch 200 | Cost: 1.248605 | Train Acc: 54.1628\n",
            "Batch 250 | Cost: 1.242144 | Train Acc: 54.3482\n",
            "Batch 300 | Cost: 1.235787 | Train Acc: 54.6901\n",
            "Batch 350 | Cost: 1.221384 | Train Acc: 55.2439\n",
            "Valid Acc: 58.2600\n",
            "\n",
            "Epoch 4:\n",
            "Batch 050 | Cost: 1.137951 | Train Acc: 58.4099\n",
            "Batch 100 | Cost: 1.119014 | Train Acc: 59.3286\n",
            "Batch 150 | Cost: 1.120288 | Train Acc: 59.0646\n",
            "Batch 200 | Cost: 1.116266 | Train Acc: 59.1185\n",
            "Batch 250 | Cost: 1.108367 | Train Acc: 59.5026\n",
            "Batch 300 | Cost: 1.103786 | Train Acc: 59.7695\n",
            "Batch 350 | Cost: 1.101706 | Train Acc: 59.8981\n",
            "Valid Acc: 63.2400\n",
            "\n",
            "Epoch 5:\n",
            "Batch 050 | Cost: 1.073538 | Train Acc: 60.8762\n",
            "Batch 100 | Cost: 1.051192 | Train Acc: 61.8116\n",
            "Batch 150 | Cost: 1.043429 | Train Acc: 62.3551\n",
            "Batch 200 | Cost: 1.032452 | Train Acc: 62.7526\n",
            "Batch 250 | Cost: 1.025669 | Train Acc: 63.0976\n",
            "Batch 300 | Cost: 1.016943 | Train Acc: 63.3358\n",
            "Batch 350 | Cost: 1.007848 | Train Acc: 63.7108\n",
            "Valid Acc: 65.3000\n",
            "\n",
            "Epoch 6:\n",
            "Batch 050 | Cost: 0.949408 | Train Acc: 65.5178\n",
            "Batch 100 | Cost: 0.941883 | Train Acc: 66.3057\n",
            "Batch 150 | Cost: 0.953175 | Train Acc: 65.8216\n",
            "Batch 200 | Cost: 0.944603 | Train Acc: 66.1769\n",
            "Batch 250 | Cost: 0.939764 | Train Acc: 66.4623\n",
            "Batch 300 | Cost: 0.937257 | Train Acc: 66.5931\n",
            "Batch 350 | Cost: 0.934746 | Train Acc: 66.7223\n",
            "Valid Acc: 69.1400\n",
            "\n",
            "Epoch 7:\n",
            "Batch 050 | Cost: 0.891565 | Train Acc: 68.4130\n",
            "Batch 100 | Cost: 0.885643 | Train Acc: 68.4870\n",
            "Batch 150 | Cost: 0.889149 | Train Acc: 68.3516\n",
            "Batch 200 | Cost: 0.891019 | Train Acc: 68.3225\n",
            "Batch 250 | Cost: 0.884286 | Train Acc: 68.6815\n",
            "Batch 300 | Cost: 0.881024 | Train Acc: 68.9395\n",
            "Batch 350 | Cost: 0.881778 | Train Acc: 68.9592\n",
            "Valid Acc: 68.7000\n",
            "\n",
            "Epoch 8:\n",
            "Batch 050 | Cost: 0.811845 | Train Acc: 71.5227\n",
            "Batch 100 | Cost: 0.834457 | Train Acc: 70.8308\n",
            "Batch 150 | Cost: 0.830201 | Train Acc: 70.8558\n",
            "Batch 200 | Cost: 0.834099 | Train Acc: 70.8450\n",
            "Batch 250 | Cost: 0.829535 | Train Acc: 71.0004\n",
            "Batch 300 | Cost: 0.827499 | Train Acc: 70.9873\n",
            "Batch 350 | Cost: 0.828466 | Train Acc: 70.9046\n",
            "Valid Acc: 71.6400\n",
            "\n",
            "Epoch 9:\n",
            "Batch 050 | Cost: 0.775578 | Train Acc: 72.6256\n",
            "Batch 100 | Cost: 0.780417 | Train Acc: 72.6021\n",
            "Batch 150 | Cost: 0.792412 | Train Acc: 72.3406\n",
            "Batch 200 | Cost: 0.795621 | Train Acc: 72.3298\n",
            "Batch 250 | Cost: 0.790681 | Train Acc: 72.5006\n",
            "Batch 300 | Cost: 0.785561 | Train Acc: 72.6095\n",
            "Batch 350 | Cost: 0.788063 | Train Acc: 72.3713\n",
            "Valid Acc: 72.2800\n",
            "\n",
            "Epoch 10:\n",
            "Batch 050 | Cost: 0.729948 | Train Acc: 74.4792\n",
            "Batch 100 | Cost: 0.750271 | Train Acc: 73.8861\n",
            "Batch 150 | Cost: 0.747823 | Train Acc: 74.0791\n",
            "Batch 200 | Cost: 0.740153 | Train Acc: 74.3043\n",
            "Batch 250 | Cost: 0.739753 | Train Acc: 74.2810\n",
            "Batch 300 | Cost: 0.739316 | Train Acc: 74.2421\n",
            "Batch 350 | Cost: 0.739277 | Train Acc: 74.1498\n",
            "Valid Acc: 72.0200\n",
            "\n",
            "Epoch 11:\n",
            "Batch 050 | Cost: 0.714458 | Train Acc: 75.4289\n",
            "Batch 100 | Cost: 0.703017 | Train Acc: 75.9050\n",
            "Batch 150 | Cost: 0.710094 | Train Acc: 75.4967\n",
            "Batch 200 | Cost: 0.705115 | Train Acc: 75.6724\n",
            "Batch 250 | Cost: 0.707857 | Train Acc: 75.6318\n",
            "Batch 300 | Cost: 0.711838 | Train Acc: 75.4594\n",
            "Batch 350 | Cost: 0.705664 | Train Acc: 75.6433\n",
            "Valid Acc: 75.1200\n",
            "\n",
            "Epoch 12:\n",
            "Batch 050 | Cost: 0.657747 | Train Acc: 76.9608\n",
            "Batch 100 | Cost: 0.661914 | Train Acc: 76.9493\n",
            "Batch 150 | Cost: 0.662587 | Train Acc: 76.9557\n",
            "Batch 200 | Cost: 0.664543 | Train Acc: 76.8540\n",
            "Batch 250 | Cost: 0.661214 | Train Acc: 76.8893\n",
            "Batch 300 | Cost: 0.666309 | Train Acc: 76.7104\n",
            "Batch 350 | Cost: 0.665831 | Train Acc: 76.8340\n",
            "Valid Acc: 74.8400\n",
            "\n",
            "Epoch 13:\n",
            "Batch 050 | Cost: 0.629041 | Train Acc: 78.1710\n",
            "Batch 100 | Cost: 0.642446 | Train Acc: 77.4288\n",
            "Batch 150 | Cost: 0.636747 | Train Acc: 77.5817\n",
            "Batch 200 | Cost: 0.637642 | Train Acc: 77.7402\n",
            "Batch 250 | Cost: 0.637610 | Train Acc: 77.7141\n",
            "Batch 300 | Cost: 0.637244 | Train Acc: 77.7902\n",
            "Batch 350 | Cost: 0.637815 | Train Acc: 77.6932\n",
            "Valid Acc: 75.2000\n",
            "\n",
            "Epoch 14:\n",
            "Batch 050 | Cost: 0.588288 | Train Acc: 79.4884\n",
            "Batch 100 | Cost: 0.593156 | Train Acc: 79.6334\n",
            "Batch 150 | Cost: 0.595807 | Train Acc: 79.5219\n",
            "Batch 200 | Cost: 0.605554 | Train Acc: 79.0734\n",
            "Batch 250 | Cost: 0.605652 | Train Acc: 79.0276\n",
            "Batch 300 | Cost: 0.613351 | Train Acc: 78.8491\n",
            "Batch 350 | Cost: 0.609542 | Train Acc: 78.9485\n",
            "Valid Acc: 75.6600\n",
            "\n",
            "Epoch 15:\n",
            "Batch 050 | Cost: 0.597401 | Train Acc: 79.7335\n",
            "Batch 100 | Cost: 0.588083 | Train Acc: 80.0820\n",
            "Batch 150 | Cost: 0.585521 | Train Acc: 80.1583\n",
            "Batch 200 | Cost: 0.579382 | Train Acc: 80.3444\n",
            "Batch 250 | Cost: 0.583671 | Train Acc: 80.1264\n",
            "Batch 300 | Cost: 0.581654 | Train Acc: 80.1261\n",
            "Batch 350 | Cost: 0.583669 | Train Acc: 79.9835\n",
            "Valid Acc: 75.6200\n",
            "\n",
            "Epoch 16:\n",
            "Batch 050 | Cost: 0.530132 | Train Acc: 81.2960\n",
            "Batch 100 | Cost: 0.543971 | Train Acc: 80.9097\n",
            "Batch 150 | Cost: 0.545607 | Train Acc: 80.9240\n",
            "Batch 200 | Cost: 0.546297 | Train Acc: 80.8808\n",
            "Batch 250 | Cost: 0.553029 | Train Acc: 80.6368\n",
            "Batch 300 | Cost: 0.556546 | Train Acc: 80.5881\n",
            "Batch 350 | Cost: 0.557176 | Train Acc: 80.6490\n",
            "Valid Acc: 76.1000\n",
            "\n",
            "Epoch 17:\n",
            "Batch 050 | Cost: 0.528065 | Train Acc: 81.9393\n",
            "Batch 100 | Cost: 0.532768 | Train Acc: 81.6213\n",
            "Batch 150 | Cost: 0.536633 | Train Acc: 81.6380\n",
            "Batch 200 | Cost: 0.534953 | Train Acc: 81.5026\n",
            "Batch 250 | Cost: 0.533375 | Train Acc: 81.5955\n",
            "Batch 300 | Cost: 0.533542 | Train Acc: 81.5563\n",
            "Batch 350 | Cost: 0.532424 | Train Acc: 81.5950\n",
            "Valid Acc: 76.7600\n",
            "\n",
            "Epoch 18:\n",
            "Batch 050 | Cost: 0.505489 | Train Acc: 82.7972\n",
            "Batch 100 | Cost: 0.495835 | Train Acc: 82.9672\n",
            "Batch 150 | Cost: 0.499465 | Train Acc: 82.7401\n",
            "Batch 200 | Cost: 0.502009 | Train Acc: 82.6648\n",
            "Batch 250 | Cost: 0.508723 | Train Acc: 82.5355\n",
            "Batch 300 | Cost: 0.509300 | Train Acc: 82.4673\n",
            "Batch 350 | Cost: 0.512823 | Train Acc: 82.3429\n",
            "Valid Acc: 75.7800\n",
            "\n",
            "Epoch 19:\n",
            "Batch 050 | Cost: 0.483709 | Train Acc: 82.7512\n",
            "Batch 100 | Cost: 0.479590 | Train Acc: 83.0832\n",
            "Batch 150 | Cost: 0.476676 | Train Acc: 83.2109\n",
            "Batch 200 | Cost: 0.476315 | Train Acc: 83.3294\n",
            "Batch 250 | Cost: 0.481801 | Train Acc: 83.1487\n",
            "Batch 300 | Cost: 0.484938 | Train Acc: 83.1032\n",
            "Batch 350 | Cost: 0.485580 | Train Acc: 83.1642\n",
            "Valid Acc: 77.6000\n",
            "\n",
            "Epoch 20:\n",
            "Batch 050 | Cost: 0.447285 | Train Acc: 84.4822\n",
            "Batch 100 | Cost: 0.453828 | Train Acc: 84.6457\n",
            "Batch 150 | Cost: 0.458573 | Train Acc: 84.3853\n",
            "Batch 200 | Cost: 0.456155 | Train Acc: 84.3944\n",
            "Batch 250 | Cost: 0.463500 | Train Acc: 84.1011\n",
            "Batch 300 | Cost: 0.466103 | Train Acc: 83.9883\n",
            "Batch 350 | Cost: 0.463821 | Train Acc: 84.0367\n",
            "Valid Acc: 77.5400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#I was surprised when initially validation accuracy is higher than training accuracy but then realized I have high drop out rate.\n",
        "print(test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELhTKW6d9cNR",
        "outputId": "8068dc92-9792-4a17-88c8-6364e67f8a5d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76.64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "To do list:\n",
        "1. Visualize result\n",
        "2. Visualize kernels, kernel maps\n",
        "3. Experiment with hyperparameters tuning, preprocessing\n",
        "4. Maybe train for more epochs and graph validation and training loss for early stopping\n",
        "5. Maybe tweaking the architecture a little bit\n",
        "6. Learn how to do distributed/parallel training like the paper suggest.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "sWnEFz8GTYxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EiiIFiMhYJf6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
