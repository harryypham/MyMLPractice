{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyO6Jm47bmdWNL9WsW6HgeAC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harryypham/MyMLPractice/blob/main/VQVAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vrvrMSTBGwMv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = torchvision.datasets.CIFAR10(root=\"data\", train=True, download=True,\n",
        "                                  transform=transforms.Compose([\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "                                  ]))\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root=\"data\", train=False, download=True,\n",
        "                                  transform=transforms.Compose([\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "                                  ]))\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size, num_workers=2)\n",
        "testloader = DataLoader(testset, batch_size=batch_size, num_workers=2)\n",
        "\n",
        "data_variance = np.var(trainset.data / 255.0)"
      ],
      "metadata": {
        "id": "XO0stWo4HPHI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d9f540d-4818-411f-b62e-1d3c43a45772"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "  def __init__(self, in_dims, hidden_dims):\n",
        "    super(ResidualBlock, self).__init__()\n",
        "    self.block = nn.Sequential(\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_dims, hidden_dims, 3, 1, 1, bias=False),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(hidden_dims, in_dims, 1, bias=False)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.block(x) + x\n",
        "\n",
        "class ResidualStack(nn.Module):\n",
        "  def __init__(self, in_dims, hidden_dims, num_layers):\n",
        "    super(ResidualStack, self).__init__()\n",
        "    self.stack = self._make_layers(in_dims, hidden_dims, num_layers)\n",
        "\n",
        "\n",
        "  def _make_layers(self, in_dims, hidden_dims, num_layers):\n",
        "    ls = []\n",
        "    for i in range(num_layers):\n",
        "      ls.append(ResidualBlock(in_dims, hidden_dims))\n",
        "\n",
        "    return nn.Sequential(*ls)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.stack(x)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, in_dims, hidden_dims, residual_hidden_dims=64):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.layer1 = nn.Sequential(\n",
        "        nn.Conv2d(in_dims, hidden_dims//2, 4, 2, 1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(hidden_dims//2, hidden_dims, 4, 2, 1),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    self.layer2 = ResidualStack(hidden_dims, residual_hidden_dims, 2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "    return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, in_dims, out_dims, residual_hidden_dims=64):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.layer1 = ResidualStack(in_dims, residual_hidden_dims, 2)\n",
        "    self.layer2 = nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_dims, 32, 4, 2, 1),\n",
        "        nn.ReLU(),\n",
        "        nn.ConvTranspose2d(32, out_dims, 4, 2, 1)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "    return x\n",
        "\n"
      ],
      "metadata": {
        "id": "ARMpbdVqHYAJ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWpL7vax2Rin",
        "outputId": "16500dca-7c40-46a7-ab4d-7a3bc7105725"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7d149381e890>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class VQEmbedding(nn.Module):\n",
        "  def __init__(self, emb_size, emb_dims, beta=0.25):\n",
        "    super().__init__()\n",
        "    self.emb_size = emb_size\n",
        "    self.emb_dims = emb_dims\n",
        "    self.beta = beta\n",
        "    self.embedding = nn.Embedding(emb_size, emb_dims)\n",
        "    self.embedding.weight.data.uniform_(-1./emb_size, 1./emb_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Current: https://github.com/zalandoresearch/pytorch-vq-vae/blob/master/vq-vae.ipynb\n",
        "    # https://juliusruseckas.github.io/ml/vq-vae.html\n",
        "    # Work out how the formula to calculate the distance work\n",
        "    x = x.permute(0, 2, 3, 1).contiguous()\n",
        "    input_shape = x.shape\n",
        "    flatten_x = x.view(-1, self.emb_dims)\n",
        "\n",
        "    distances = torch.sum(flatten_x ** 2, dim=1, keepdim=True) \\\n",
        "                + torch.sum(self.embedding.weight**2, dim=1) \\\n",
        "                - 2 * torch.matmul(flatten_x, self.embedding.weight.t())\n",
        "\n",
        "    indices = torch.argmin(distances, dim=1).unsqueeze(1)\n",
        "    encodings = torch.zeros(indices.shape[0], self.emb_size).to(device)\n",
        "    encodings.scatter_(1, indices, 1)\n",
        "\n",
        "\n",
        "    # Quantize and unflatten\n",
        "    quantized = torch.matmul(encodings, self.embedding.weight).view(input_shape)\n",
        "\n",
        "    e_latent_loss = F.mse_loss(quantized.detach(), x)\n",
        "    q_latent_loss = F.mse_loss(quantized, x.detach())\n",
        "    loss = q_latent_loss + self.beta * e_latent_loss\n",
        "\n",
        "    # Make the gradient with respect to inputs be equal to the gradient with respect to quantized latents (cool trick!)\n",
        "    quantized = x + (quantized - x).detach()\n",
        "    quantized = quantized.permute(0, 3, 1, 2).contiguous()\n",
        "\n",
        "    return quantized, loss"
      ],
      "metadata": {
        "id": "NK59Cro_YLbF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VQVAE(nn.Module):\n",
        "  def __init__(self, emb_size, emb_dims, hidden_dims, residual_hidden_dims):\n",
        "    super().__init__()\n",
        "    self.encoder = Encoder(3, hidden_dims)\n",
        "    self.pre_vq_conv = nn.Conv2d(hidden_dims, emb_dims, 1, 1)\n",
        "    self.decoder = Decoder(emb_dims, 3)\n",
        "    self.vq = VQEmbedding(emb_size, emb_dims)\n",
        "\n",
        "  def forward(self, x):\n",
        "    z_e = self.encoder(x)\n",
        "    z_e = self.pre_vq_conv(z_e)\n",
        "    z_q, loss = self.vq(z_e)\n",
        "    x_recon = self.decoder(z_q)\n",
        "    return x_recon, loss"
      ],
      "metadata": {
        "id": "XFesQLI4Yh5l"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand((16, 2, 8, 8))\n",
        "targets = torch.rand((1024, 2))"
      ],
      "metadata": {
        "id": "SEZPXix5D78f"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "embed = VQEmbedding(20, 2)\n",
        "embed.zero_grad()\n",
        "out = embed(x)\n",
        "criterion = nn.MSELoss()\n",
        "loss = criterion(out, targets)\n",
        "loss.backward()\n",
        "print(embed.embedding.weight.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zq6X58RT2tXW",
        "outputId": "c6a72c2e-ab51-4494-aae5-d3e71b2f9b79"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000],\n",
            "        [-0.0014, -0.0018],\n",
            "        [-0.0029, -0.0044],\n",
            "        [ 0.0000,  0.0000],\n",
            "        [-0.1275, -0.1530],\n",
            "        [ 0.0000,  0.0000],\n",
            "        [-0.2329, -0.2252],\n",
            "        [ 0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000],\n",
            "        [-0.1104, -0.0966],\n",
            "        [ 0.0000,  0.0000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand((1, 1, 32, 32))\n",
        "encode = Encoder(1, 64)\n",
        "out = encode(x)\n",
        "print(out.shape)\n",
        "decode = Decoder(64, 3)\n",
        "out = decode(out)\n",
        "print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_NZUocDMo8A",
        "outputId": "22ff03a4-73b9-4648-d879-2ebef68d58c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 64, 8, 8])\n",
            "torch.Size([1, 3, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand((16, 64, 8, 8))\n",
        "flat_x = x.permute(0, 2, 3, 1).reshape(-1, 64)\n",
        "print(flat_x.shape)\n",
        "#Imagine image have 64 channels and for each pixel of that image, we find the vector closest to it\n",
        "\n",
        "emb_table = nn.Embedding(512, 64)\n",
        "emb_table.weight.data.uniform_(-1, 1)\n",
        "\n",
        "distances = (\n",
        "            (flat_x ** 2).sum(1, keepdim=True)\n",
        "            - 2 * flat_x @ emb_table.weight.t()\n",
        "            + (emb_table.weight.t() ** 2).sum(1)\n",
        "        )\n",
        "\n",
        "print(distances.shape)\n",
        "encoding_indices = distances.argmin(1)\n",
        "quantizied_x = F.embedding(encoding_indices, emb_table.weight)\n",
        "print(emb_table.weight.shape)\n",
        "print(quantizied_x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FNo13QzEl10",
        "outputId": "2397b641-d257-4c7e-cbf4-ac42e91ab179"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1024, 64])\n",
            "torch.Size([1024, 512])\n",
            "torch.Size([512, 64])\n",
            "torch.Size([1024, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_hiddens = 128\n",
        "num_residual_hiddens = 256\n",
        "embedding_dim = 64\n",
        "num_embeddings = 512\n",
        "num_epochs = 20\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "KyxUaX52YcnC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VQVAE(num_embeddings, embedding_dim, num_hiddens, num_residual_hiddens).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
        "\n",
        "loss_history = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  train_loss = 0\n",
        "  for batch_idx, (inputs, _) in enumerate(trainloader):\n",
        "    inputs = inputs.to(device)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs, vq_loss = model(inputs)\n",
        "    loss = vq_loss + (F.mse_loss(outputs, inputs) / data_variance)\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    loss_history.append(loss.item())\n",
        "    train_loss += loss.item()\n",
        "\n",
        "    if (not batch_idx % 200) and batch_idx != 0:\n",
        "            print ('Batch %03d | Cost: %.6f'\n",
        "                  %(batch_idx, train_loss/(batch_idx+1)))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jozd5oOibF_f",
        "outputId": "f0df07cf-0f3f-4426-f521-48a4e6ba9f80"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 200 | Cost: 110525.076168\n",
            "Batch 400 | Cost: 101228.419506\n",
            "Batch 600 | Cost: 82433.370400\n",
            "Batch 800 | Cost: 69752.308293\n",
            "Batch 1000 | Cost: 61206.350148\n",
            "Batch 1200 | Cost: 53704.884954\n",
            "Batch 1400 | Cost: 47308.566809\n",
            "Batch 200 | Cost: 6037.409195\n",
            "Batch 400 | Cost: 6717.036955\n",
            "Batch 600 | Cost: 7551.921424\n",
            "Batch 800 | Cost: 7667.910918\n",
            "Batch 1000 | Cost: 8307.086652\n",
            "Batch 1200 | Cost: 8130.532272\n",
            "Batch 1400 | Cost: 7829.706780\n",
            "Batch 200 | Cost: 3401.278342\n",
            "Batch 400 | Cost: 3322.945808\n",
            "Batch 600 | Cost: 3308.120538\n",
            "Batch 800 | Cost: 3116.768793\n",
            "Batch 1000 | Cost: 2931.333768\n",
            "Batch 1200 | Cost: 2756.529744\n",
            "Batch 1400 | Cost: 2603.009650\n",
            "Batch 200 | Cost: 1300.245091\n",
            "Batch 400 | Cost: 1256.102798\n",
            "Batch 600 | Cost: 1241.405489\n",
            "Batch 800 | Cost: 1306.290302\n",
            "Batch 1000 | Cost: 1282.126504\n",
            "Batch 1200 | Cost: 1236.776047\n",
            "Batch 1400 | Cost: 1201.608634\n",
            "Batch 200 | Cost: 963.982366\n",
            "Batch 400 | Cost: 986.937480\n",
            "Batch 600 | Cost: 1003.591512\n",
            "Batch 800 | Cost: 982.633514\n",
            "Batch 1000 | Cost: 954.831875\n",
            "Batch 1200 | Cost: 924.374925\n",
            "Batch 1400 | Cost: 891.796634\n",
            "Batch 200 | Cost: 696.522991\n",
            "Batch 400 | Cost: 651.824130\n",
            "Batch 600 | Cost: 621.484365\n",
            "Batch 800 | Cost: 609.217382\n",
            "Batch 1000 | Cost: 587.485439\n",
            "Batch 1200 | Cost: 577.657665\n",
            "Batch 1400 | Cost: 556.410211\n",
            "Batch 200 | Cost: 441.893747\n",
            "Batch 400 | Cost: 444.285849\n",
            "Batch 600 | Cost: 409.803171\n",
            "Batch 800 | Cost: 393.153094\n",
            "Batch 1000 | Cost: 386.752783\n",
            "Batch 1200 | Cost: 379.790261\n",
            "Batch 1400 | Cost: 369.029650\n",
            "Batch 200 | Cost: 354.127142\n",
            "Batch 400 | Cost: 344.931035\n",
            "Batch 600 | Cost: 334.664024\n",
            "Batch 800 | Cost: 326.784737\n",
            "Batch 1000 | Cost: 325.428398\n",
            "Batch 1200 | Cost: 319.349503\n",
            "Batch 1400 | Cost: 312.642178\n",
            "Batch 200 | Cost: 267.227528\n",
            "Batch 400 | Cost: 270.153806\n",
            "Batch 600 | Cost: 268.618088\n",
            "Batch 800 | Cost: 275.100125\n",
            "Batch 1000 | Cost: 272.318764\n",
            "Batch 1200 | Cost: 267.436529\n",
            "Batch 1400 | Cost: 262.842510\n",
            "Batch 200 | Cost: 235.049535\n",
            "Batch 400 | Cost: 237.005156\n",
            "Batch 600 | Cost: 236.039801\n",
            "Batch 800 | Cost: 234.404233\n",
            "Batch 1000 | Cost: 235.832545\n",
            "Batch 1200 | Cost: 235.424107\n",
            "Batch 1400 | Cost: 235.562083\n",
            "Batch 200 | Cost: 236.683892\n",
            "Batch 400 | Cost: 236.389475\n",
            "Batch 600 | Cost: 237.552770\n",
            "Batch 800 | Cost: 233.986469\n",
            "Batch 1000 | Cost: 235.384351\n",
            "Batch 1200 | Cost: 234.308157\n",
            "Batch 1400 | Cost: 233.485429\n",
            "Batch 200 | Cost: 225.700586\n",
            "Batch 400 | Cost: 229.588058\n",
            "Batch 600 | Cost: 229.134903\n",
            "Batch 800 | Cost: 228.918755\n",
            "Batch 1000 | Cost: 230.606630\n",
            "Batch 1200 | Cost: 231.027653\n",
            "Batch 1400 | Cost: 231.125500\n",
            "Batch 200 | Cost: 237.495013\n",
            "Batch 400 | Cost: 237.767190\n",
            "Batch 600 | Cost: 236.840739\n",
            "Batch 800 | Cost: 234.826217\n",
            "Batch 1000 | Cost: 234.638080\n",
            "Batch 1200 | Cost: 233.880446\n",
            "Batch 1400 | Cost: 232.253125\n",
            "Batch 200 | Cost: 220.143145\n",
            "Batch 400 | Cost: 220.089562\n",
            "Batch 600 | Cost: 219.558809\n",
            "Batch 800 | Cost: 217.783597\n",
            "Batch 1000 | Cost: 218.403988\n",
            "Batch 1200 | Cost: 217.580521\n",
            "Batch 1400 | Cost: 216.534090\n",
            "Batch 200 | Cost: 210.226272\n",
            "Batch 400 | Cost: 208.575048\n",
            "Batch 600 | Cost: 206.629373\n",
            "Batch 800 | Cost: 205.319785\n",
            "Batch 1000 | Cost: 204.948914\n",
            "Batch 1200 | Cost: 204.332658\n",
            "Batch 1400 | Cost: 202.731751\n",
            "Batch 200 | Cost: 195.476132\n",
            "Batch 400 | Cost: 192.800100\n",
            "Batch 600 | Cost: 193.053101\n",
            "Batch 800 | Cost: 191.526695\n",
            "Batch 1000 | Cost: 191.537562\n",
            "Batch 1200 | Cost: 190.806493\n",
            "Batch 1400 | Cost: 189.417355\n",
            "Batch 200 | Cost: 188.327970\n",
            "Batch 400 | Cost: 183.424214\n",
            "Batch 600 | Cost: 181.132014\n",
            "Batch 800 | Cost: 179.438749\n",
            "Batch 1000 | Cost: 178.842666\n",
            "Batch 1200 | Cost: 178.522841\n",
            "Batch 1400 | Cost: 177.131938\n",
            "Batch 200 | Cost: 172.744341\n",
            "Batch 400 | Cost: 170.632981\n",
            "Batch 600 | Cost: 168.336217\n",
            "Batch 800 | Cost: 165.580728\n",
            "Batch 1000 | Cost: 165.249573\n",
            "Batch 1200 | Cost: 164.257100\n",
            "Batch 1400 | Cost: 162.679741\n",
            "Batch 200 | Cost: 147.425770\n",
            "Batch 400 | Cost: 144.298873\n",
            "Batch 600 | Cost: 142.489821\n",
            "Batch 800 | Cost: 140.528216\n",
            "Batch 1000 | Cost: 140.053789\n",
            "Batch 1200 | Cost: 138.864475\n",
            "Batch 1400 | Cost: 137.606164\n",
            "Batch 200 | Cost: 123.625486\n",
            "Batch 400 | Cost: 122.978320\n",
            "Batch 600 | Cost: 123.004851\n",
            "Batch 800 | Cost: 121.608289\n",
            "Batch 1000 | Cost: 122.292421\n",
            "Batch 1200 | Cost: 122.278942\n",
            "Batch 1400 | Cost: 121.362407\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X1qdOW_bmHJS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}