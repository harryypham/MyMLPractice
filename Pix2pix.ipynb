{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyMenQfJwGX5J9qkkZOMdFAC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harryypham/MyMLPractice/blob/main/Pix2pix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BDkmwGNPnzT_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision.utils import save_image\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "TRAIN_DIR = \"data/data/train\"\n",
        "VAL_DIR = \"data/data/val\"\n",
        "LEARNING_RATE = 2e-4\n",
        "BATCH_SIZE = 16\n",
        "NUM_WORKERS = 2\n",
        "IMAGE_SIZE = 256\n",
        "CHANNELS_IMG = 3\n",
        "L1_LAMBDA = 100\n",
        "LAMBDA_GP = 10\n",
        "NUM_EPOCHS = 500\n",
        "\n",
        "both_transform = A.Compose(\n",
        "    [A.Resize(width=256, height=256), A.HorizontalFlip(p=0.5)], additional_targets={\"image0\": \"image\"},\n",
        ")\n",
        "\n",
        "transform_only_input = A.Compose(\n",
        "    [\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.ColorJitter(p=0.2),\n",
        "        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255.0,),\n",
        "        ToTensorV2(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "transform_only_mask = A.Compose(\n",
        "    [\n",
        "        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255.0,),\n",
        "        ToTensorV2(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "def save_some_examples(gen, val_loader, epoch, folder):\n",
        "    x, y = next(iter(val_loader))\n",
        "    x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "    gen.eval()\n",
        "    with torch.no_grad():\n",
        "        y_fake = gen(x)\n",
        "        y_fake = y_fake * 0.5 + 0.5  # remove normalization#\n",
        "        save_image(y_fake, folder + f\"/y_gen_{epoch}.png\")\n",
        "        save_image(x * 0.5 + 0.5, folder + f\"/input_{epoch}.png\")\n",
        "        if epoch == 1:\n",
        "            save_image(y * 0.5 + 0.5, folder + f\"/label_{epoch}.png\")\n",
        "    gen.train()"
      ],
      "metadata": {
        "id": "Dn_eFSysGL7v"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, root_dir):\n",
        "    self.root_dir = root_dir\n",
        "    self.list_files = os.listdir(root_dir)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.list_files)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    img_file = self.list_files[index]\n",
        "    img_path = os.path.join(self.root_dir, img_file)\n",
        "    image = np.array(Image.open(img_path))\n",
        "    input_image, target_image = image[:, :512, :], image[:, 512:, :]\n",
        "\n",
        "    augmentations = both_transform(image=input_image, image0=target_image)\n",
        "    input_image, target_image = augmentations[\"image\"], augmentations[\"image0\"]\n",
        "\n",
        "    input_image = transform_only_input(image=input_image)[\"image\"]\n",
        "    target_image = transform_only_input(image=target_image)[\"image\"]\n",
        "\n",
        "    return input_image, target_image"
      ],
      "metadata": {
        "id": "0Ymrqdp5Dq1X"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ET71TVCoDqxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, stride):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 4, stride, bias=False, padding_mode=\"reflect\"),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.LeakyReLU(0.2)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.conv(x)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, in_channels=3, features=[64, 128, 256, 512]):\n",
        "    super().__init__()\n",
        "    self.initial = nn.Sequential(\n",
        "        nn.Conv2d(in_channels*2, features[0], 4, 2, 1, padding_mode=\"reflect\"),\n",
        "        nn.LeakyReLU(0.2),\n",
        "    )\n",
        "\n",
        "    layers = []\n",
        "    in_channels = features[0]\n",
        "    for feature in features[1:]:\n",
        "      layers.append(\n",
        "          Conv(in_channels, feature, stride=1 if feature == features[-1] else 2)\n",
        "      )\n",
        "      in_channels = feature\n",
        "    layers.append(\n",
        "        nn.Conv2d(in_channels, 1, 4, 1, 1, padding_mode=\"reflect\")\n",
        "    )\n",
        "\n",
        "    self.model = nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x, y):\n",
        "    x = torch.cat([x, y], dim=1)\n",
        "    x = self.initial(x)\n",
        "    x = self.model(x)\n",
        "    return x\n",
        "\n"
      ],
      "metadata": {
        "id": "cehHO16krDYA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, down=True, act=\"relu\", use_dropout=False):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 4, 2, 1, bias=False, padding_mode=\"reflect\")\n",
        "        if down\n",
        "        else nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1, bias=False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU() if act == \"relu\" else nn.LeakyReLU(0.2),\n",
        "    )\n",
        "    self.use_dropout = use_dropout\n",
        "    self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    return self.dropout(x) if self.use_dropout else x\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, in_channels=3, features=64):\n",
        "    super().__init__()\n",
        "    self.initial_down = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, features, 4, 2, 1, padding_mode=\"reflect\"),\n",
        "        nn.LeakyReLU(0.2),\n",
        "    )\n",
        "\n",
        "    self.down1 = Block(features, features*2, down=True, act=\"leaky\")\n",
        "    self.down2 = Block(features*2, features*4, down=True, act=\"leaky\")\n",
        "    self.down3 = Block(features*4, features*8, down=True, act=\"leaky\")\n",
        "    self.down4 = Block(features*8, features*8, down=True, act=\"leaky\")\n",
        "    self.down5 = Block(features*8, features*8, down=True, act=\"leaky\")\n",
        "    self.down6 = Block(features*8, features*8, down=True, act=\"leaky\")\n",
        "\n",
        "    self.bottleneck = nn.Sequential(\n",
        "        nn.Conv2d(features*8, features*8, 4, 2, 1, padding_mode=\"reflect\"),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.up1 = Block(features*8, features*8, down=False, act=\"relu\", use_dropout=True)\n",
        "    self.up2 = Block(features*8*2, features*8, down=False, act=\"relu\", use_dropout=True)\n",
        "    self.up3 = Block(features*8*2, features*8, down=False, act=\"relu\", use_dropout=True)\n",
        "    self.up4 = Block(features*8*2, features*8, down=False, act=\"relu\", use_dropout=False)\n",
        "    self.up5 = Block(features*8*2, features*4, down=False, act=\"relu\", use_dropout=False)\n",
        "    self.up6 = Block(features*4*2, features*2, down=False, act=\"relu\", use_dropout=False)\n",
        "    self.up7 = Block(features*2*2, features, down=False, act=\"relu\", use_dropout=False)\n",
        "    self.final_up = nn.Sequential(\n",
        "        nn.ConvTranspose2d(features*2, in_channels, 4, 2, 1),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    d1 = self.initial_down(x)\n",
        "    d2 = self.down1(d1)\n",
        "    d3 = self.down2(d2)\n",
        "    d4 = self.down3(d3)\n",
        "    d5 = self.down4(d4)\n",
        "    d6 = self.down5(d5)\n",
        "    d7 = self.down6(d6)\n",
        "\n",
        "    bottleneck = self.bottleneck(d7)\n",
        "\n",
        "    u1 = self.up1(bottleneck)\n",
        "    u2 = self.up2(torch.cat([u1, d7], dim=1))\n",
        "    u3 = self.up3(torch.cat([u2, d6], dim=1))\n",
        "    u4 = self.up4(torch.cat([u3, d5], dim=1))\n",
        "    u5 = self.up5(torch.cat([u4, d4], dim=1))\n",
        "    u6 = self.up6(torch.cat([u5, d3], dim=1))\n",
        "    u7 = self.up7(torch.cat([u6, d2], dim=1))\n",
        "    out = self.final_up(torch.cat([u7, d1], dim=1))\n",
        "    return out\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2pblxMFou9aY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_fn(disc, gen, loader, opt_disc, opt_gen, l1, bce):\n",
        "  loop = tqdm(loader, leave=True)\n",
        "  d_loss, g_loss = 0, 0\n",
        "  for idx, (x, y) in enumerate(loop):\n",
        "    x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "\n",
        "    y_fake = gen(x)\n",
        "    D_real = disc(x, y)\n",
        "    D_fake = disc(x, y_fake.detach())\n",
        "    D_real_loss = bce(D_real, torch.ones_like(D_real))\n",
        "    D_fake_loss = bce(D_fake, torch.zeros_like(D_fake))\n",
        "    D_loss = (D_real_loss + D_fake_loss) / 2\n",
        "\n",
        "    disc.zero_grad()\n",
        "    D_loss.backward()\n",
        "    opt_disc.step()\n",
        "\n",
        "    D_fake = disc(x, y_fake)\n",
        "    G_fake_loss = bce(D_fake, torch.ones_like(D_fake))\n",
        "    L1 = l1(y_fake, y) * L1_LAMBDA\n",
        "    G_loss = G_fake_loss + L1\n",
        "\n",
        "    gen.zero_grad()\n",
        "    G_loss.backward()\n",
        "    opt_gen.step()\n",
        "    d_loss += D_loss.item()\n",
        "    g_loss += G_loss.item()\n",
        "\n",
        "    loop.set_description(\"D_loss: %.6f | G_loss: %.6f\" % (d_loss/((idx+1)*BATCH_SIZE), g_loss/((idx+1)*BATCH_SIZE)))\n"
      ],
      "metadata": {
        "id": "rWjGreGGH860"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  disc = Discriminator(in_channels=3).to(DEVICE)\n",
        "  gen = Generator(in_channels=3).to(DEVICE)\n",
        "  opt_disc = optim.Adam(disc.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
        "  opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
        "  BCE = nn.BCEWithLogitsLoss()\n",
        "  L1_LOSS = nn.L1Loss()\n",
        "\n",
        "  train_dataset = CustomDataset(TRAIN_DIR)\n",
        "  train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
        "  valset = CustomDataset(VAL_DIR)\n",
        "  val_loader = DataLoader(valset, batch_size=1, shuffle=False)\n",
        "\n",
        "  for epoch in range(NUM_EPOCHS):\n",
        "    train_fn(disc, gen, train_loader, opt_disc, opt_gen, L1_LOSS, BCE)\n",
        "\n",
        "    save_some_examples(gen, val_loader, epoch, folder=\"eval\")"
      ],
      "metadata": {
        "id": "0djEaB7FIPB4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfNVYXaFPujJ",
        "outputId": "0812384f-ce00-48d4-8e6c-68d5714d3d6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "D_loss: 0.026193 | G_loss: 0.976092: 100%|██████████| 889/889 [02:31<00:00,  5.88it/s]\n",
            "D_loss: 0.028710 | G_loss: 0.879163: 100%|██████████| 889/889 [02:30<00:00,  5.89it/s]\n",
            "D_loss: 0.028967 | G_loss: 0.882265: 100%|██████████| 889/889 [02:31<00:00,  5.89it/s]\n",
            "D_loss: 0.030519 | G_loss: 0.868943: 100%|██████████| 889/889 [02:31<00:00,  5.88it/s]\n",
            "D_loss: 0.029786 | G_loss: 0.859628:  83%|████████▎ | 740/889 [02:05<00:25,  5.91it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vwlMZwkkScmY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}