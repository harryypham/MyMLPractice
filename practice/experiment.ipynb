{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOxn/OpEA7IN/wOm61iO+6e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harryypham/MyMLPractice/blob/main/practice/experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchinfo import summary\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import random, os\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = True"
      ],
      "metadata": {
        "id": "jCmxYNdVbn5x"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "cukEzwewzTu5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = torchvision.datasets.CIFAR10(\"data\", train=True, download=True)\n",
        "test_set = torchvision.datasets.CIFAR10(\"data\", train=False, download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6eIaZBd1hkA",
        "outputId": "cd81ffcb-071b-4e4e-da6e-eee6f741f832"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:12<00:00, 13188017.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "\n",
        "def load_data(transform, batch_size=32):\n",
        "  train_set = torchvision.datasets.CIFAR10(\"data\", train=True, transform=transform)\n",
        "  test_set = torchvision.datasets.CIFAR10(\"data\", train=False, transform=transform)\n",
        "\n",
        "  num_classes = len(train_set.classes)\n",
        "\n",
        "  train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True, worker_init_fn=seed_worker)\n",
        "  test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True, worker_init_fn=seed_worker)\n",
        "\n",
        "  return train_loader, test_loader, num_classes\n",
        "\n",
        "def train_one_epoch(model, train_loader, criterion, optimizer, device):\n",
        "  model.train()\n",
        "  pbar = tqdm(train_loader, leave=True)\n",
        "  running_loss = 0.0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  for batch_idx, (inputs, targets) in enumerate(pbar):\n",
        "    inputs = inputs.to(device)\n",
        "    targets = targets.to(device)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    _, preds = outputs.max(1)\n",
        "    correct += preds.eq(targets).sum().item()\n",
        "    total += targets.size(0)\n",
        "\n",
        "    pbar.set_postfix_str(f\"train_loss: {(running_loss/total):.4f} | train_acc: {(correct * 100/total):.4f}\", refresh=True)\n",
        "\n",
        "  return running_loss/total, (correct/total) * 100\n",
        "\n",
        "\n",
        "def train(model, train_loader, criterion, optimizer, epochs, device):\n",
        "  train_loss = []\n",
        "  train_acc = []\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch + 1}: \")\n",
        "\n",
        "    loss, acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
        "\n",
        "    train_loss.append(loss)\n",
        "    train_acc.append(acc)\n",
        "\n",
        "  return train_loss, train_acc\n",
        "\n",
        "\n",
        "def test(model, test_loader, device):\n",
        "  model.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "\n",
        "\n",
        "      _, preds = outputs.max(1)\n",
        "      correct += preds.eq(targets).sum().item()\n",
        "      total += targets.size(0)\n",
        "\n",
        "  return (correct/total) * 100\n"
      ],
      "metadata": {
        "id": "DqGKZDqm17Cu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_resnet  = torchvision.models.ResNet50_Weights.DEFAULT\n",
        "\n",
        "resnet_transforms = weight_resnet.transforms()\n",
        "\n",
        "print(resnet_transforms)\n",
        "\n",
        "train_loader, test_loader, num_classes = load_data(resnet_transforms)\n",
        "\n",
        "print(num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jA4XpwF80O7M",
        "outputId": "1a16cf4d-9de6-4a07-b604-ea09184cb6d5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ImageClassification(\n",
            "    crop_size=[224]\n",
            "    resize_size=[232]\n",
            "    mean=[0.485, 0.456, 0.406]\n",
            "    std=[0.229, 0.224, 0.225]\n",
            "    interpolation=InterpolationMode.BILINEAR\n",
            ")\n",
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model = torchvision.models.resnet50(weights=weight_resnet, progress=True)\n",
        "\n",
        "for param in resnet_model.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "resnet_model.fc = nn.Sequential(\n",
        "    nn.Linear(2048, 1024),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Linear(1024, num_classes)\n",
        ")\n",
        "\n",
        "\n",
        "# summary(resnet_model, input_size=(32, 3, 224, 224), col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"])\n"
      ],
      "metadata": {
        "id": "8OnJuwlN1Nzd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(resnet_model.parameters(), lr=1e-4)\n",
        "\n",
        "train_loss, train_acc = train(resnet_model, train_loader, loss_fn, optimizer, 5, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LndEL2MOA9tw",
        "outputId": "8239602d-b2e1-4993-8aa7-d25cd2a8f3b7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [01:04<00:00, 24.05it/s, train_loss: 0.0265 | train_acc: 72.9140]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [01:04<00:00, 24.27it/s, train_loss: 0.0191 | train_acc: 79.2140]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [01:04<00:00, 24.27it/s, train_loss: 0.0175 | train_acc: 80.8220]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [01:04<00:00, 24.33it/s, train_loss: 0.0167 | train_acc: 81.6080]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [01:04<00:00, 24.13it/s, train_loss: 0.0161 | train_acc: 82.4440]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNSXYqrmG9Gi",
        "outputId": "6dcbdb35-242d-4735-afcd-c97249a56ae0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[72.914, 79.214, 80.822, 81.608, 82.44399999999999]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc = test(resnet_model, test_loader, device)\n",
        "test_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SubsJbuIlET",
        "outputId": "7f959665-fc99-4cd0-dea7-73efa726002b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81.74"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bM4j3CT9L5H9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}