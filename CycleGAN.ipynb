{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyNnypa2dPSeltGlQYKV5OdA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harryypham/MyMLPractice/blob/main/CycleGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tqXcMna6e5yn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#https://www.kaggle.com/datasets/balraj98/horse2zebra-dataset\n",
        "def rename(dir):\n",
        "  path = f\"/content/dataset/{dir}\"\n",
        "  i = 0\n",
        "  for filename in os.listdir(path):\n",
        "      f = os.path.join(path, filename)\n",
        "      os.rename(f, os.path.join(path, f'{i}.jpg'))\n",
        "      i += 1\n",
        "\n",
        "rename(\"trainA\")\n",
        "rename(\"trainB\")\n",
        "rename(\"testA\")\n",
        "rename(\"testB\")"
      ],
      "metadata": {
        "id": "gHTvuDNroi75"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HorseZebraDataset(Dataset):\n",
        "    def __init__(self, root_zebra, root_horse, transform=None):\n",
        "        self.root_zebra = root_zebra\n",
        "        self.root_horse = root_horse\n",
        "        self.transform = transform\n",
        "\n",
        "        self.zebra_images = os.listdir(root_zebra)\n",
        "        self.horse_images = os.listdir(root_horse)\n",
        "        self.length_dataset = max(len(self.zebra_images), len(self.horse_images)) # 1000, 1500\n",
        "        self.zebra_len = len(self.zebra_images)\n",
        "        self.horse_len = len(self.horse_images)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length_dataset\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        zebra_img = self.zebra_images[index % self.zebra_len]\n",
        "        horse_img = self.horse_images[index % self.horse_len]\n",
        "\n",
        "        zebra_path = os.path.join(self.root_zebra, zebra_img)\n",
        "        horse_path = os.path.join(self.root_horse, horse_img)\n",
        "\n",
        "        zebra_img = np.array(Image.open(zebra_path).convert(\"RGB\"))\n",
        "        horse_img = np.array(Image.open(horse_path).convert(\"RGB\"))\n",
        "\n",
        "        if self.transform:\n",
        "            augmentations = self.transform(image=zebra_img, image0=horse_img)\n",
        "            zebra_img = augmentations[\"image\"]\n",
        "            horse_img = augmentations[\"image0\"]\n",
        "\n",
        "        return zebra_img, horse_img\n",
        "\n",
        "transforms = A.Compose(\n",
        "    [\n",
        "        A.Resize(width=256, height=256),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255),\n",
        "        ToTensorV2(),\n",
        "    ],\n",
        "    additional_targets={\"image0\": \"image\"},\n",
        ")"
      ],
      "metadata": {
        "id": "yB6L-whryhEf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, stride, padding, pad_reflect=True, res_block=False):\n",
        "    super().__init__()\n",
        "    self.res_block = res_block\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.ReflectionPad2d(padding),\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size, stride),\n",
        "        nn.InstanceNorm2d(out_channels),\n",
        "        nn.ReLU(),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    if self.res_block:\n",
        "      return self.conv(x) + x\n",
        "    return self.conv(x)\n",
        "\n",
        "class ConvTranspose(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, stride, padding, pad_reflect=True):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, output_padding=padding),\n",
        "        nn.InstanceNorm2d(out_channels),\n",
        "        nn.ReLU(),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.conv(x)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, num_res_block=6):\n",
        "    super().__init__()\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "\n",
        "    self.encoder = self._make_encoder()\n",
        "    self.decoder = self._make_decoder()\n",
        "    self.bottleneck = self._make_bottleneck(num_res_block)\n",
        "\n",
        "  def _make_encoder(self):\n",
        "    net = nn.Sequential(\n",
        "        Conv(self.in_channels, 64, 7, 1, 3),\n",
        "        Conv(64, 128, 3, 2, 1),\n",
        "        Conv(128, 256, 3, 2, 1)\n",
        "    )\n",
        "    return net\n",
        "\n",
        "  def _make_bottleneck(self, num_blocks):\n",
        "    ls = []\n",
        "    for _ in range(num_blocks):\n",
        "      ls.append(Conv(256, 256, 3, 1, 1, res_block=True))\n",
        "    return nn.Sequential(*ls)\n",
        "\n",
        "\n",
        "  def _make_decoder(self):\n",
        "    net = nn.Sequential(\n",
        "        ConvTranspose(256, 128, 3, 2, 1),\n",
        "        ConvTranspose(128, 64, 3, 2, 1),\n",
        "        Conv(64, 3, 7, 1, 3)\n",
        "    )\n",
        "    return net\n",
        "  def forward(self, x):\n",
        "    x = self.encoder(x)\n",
        "    x = self.bottleneck(x)\n",
        "    x = self.decoder(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "dyTplwRAfoQ0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DConv(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 4, 2),\n",
        "        nn.InstanceNorm2d(out_channels),\n",
        "        nn.LeakyReLU(0.2),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.conv(x)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, in_channels):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        DConv(in_channels, 64),\n",
        "        DConv(64, 128),\n",
        "        DConv(128, 256),\n",
        "        DConv(256, 512),\n",
        "        nn.Conv2d(512, 1, 4, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.net(x)"
      ],
      "metadata": {
        "id": "vUMNefiJlqT9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_fn(\n",
        "    disc_H, disc_Z, gen_Z, gen_H, loader, opt_disc, opt_gen, l1, mse, device):\n",
        "    H_reals = 0\n",
        "    H_fakes = 0\n",
        "    loop = tqdm(loader, leave=True)\n",
        "    LAMBDA_IDENTITY = 0.0\n",
        "    LAMBDA_CYCLE = 10\n",
        "\n",
        "    for idx, (zebra, horse) in enumerate(loop):\n",
        "        zebra = zebra.to(device)\n",
        "        horse = horse.to(device)\n",
        "\n",
        "        # Train Discriminators H and Z\n",
        "        fake_horse = gen_H(zebra)\n",
        "        D_H_real = disc_H(horse)\n",
        "        D_H_fake = disc_H(fake_horse.detach())\n",
        "        H_reals += D_H_real.mean().item()\n",
        "        H_fakes += D_H_fake.mean().item()\n",
        "        D_H_real_loss = mse(D_H_real, torch.ones_like(D_H_real))\n",
        "        D_H_fake_loss = mse(D_H_fake, torch.zeros_like(D_H_fake))\n",
        "        D_H_loss = D_H_real_loss + D_H_fake_loss\n",
        "\n",
        "        fake_zebra = gen_Z(horse)\n",
        "        D_Z_real = disc_Z(zebra)\n",
        "        D_Z_fake = disc_Z(fake_zebra.detach())\n",
        "        D_Z_real_loss = mse(D_Z_real, torch.ones_like(D_Z_real))\n",
        "        D_Z_fake_loss = mse(D_Z_fake, torch.zeros_like(D_Z_fake))\n",
        "        D_Z_loss = D_Z_real_loss + D_Z_fake_loss\n",
        "\n",
        "        # put it togethor\n",
        "        D_loss = (D_H_loss + D_Z_loss) / 2\n",
        "\n",
        "        opt_disc.zero_grad()\n",
        "        D_loss.backward()\n",
        "        opt_disc.step()\n",
        "\n",
        "        # Train Generators H and Z\n",
        "        # adversarial loss for both generators\n",
        "        D_H_fake = disc_H(fake_horse)\n",
        "        D_Z_fake = disc_Z(fake_zebra)\n",
        "        loss_G_H = mse(D_H_fake, torch.ones_like(D_H_fake))\n",
        "        loss_G_Z = mse(D_Z_fake, torch.ones_like(D_Z_fake))\n",
        "\n",
        "        # cycle loss\n",
        "        cycle_zebra = gen_Z(fake_horse)\n",
        "        cycle_horse = gen_H(fake_zebra)\n",
        "        cycle_zebra_loss = l1(zebra, cycle_zebra)\n",
        "        cycle_horse_loss = l1(horse, cycle_horse)\n",
        "\n",
        "        # identity loss (remove these for efficiency if you set lambda_identity=0)\n",
        "        identity_zebra = gen_Z(zebra)\n",
        "        identity_horse = gen_H(horse)\n",
        "        identity_zebra_loss = l1(zebra, identity_zebra)\n",
        "        identity_horse_loss = l1(horse, identity_horse)\n",
        "\n",
        "        # add all togethor\n",
        "        G_loss = (\n",
        "            loss_G_Z\n",
        "            + loss_G_H\n",
        "            + cycle_zebra_loss * LAMBDA_CYCLE\n",
        "            + cycle_horse_loss * LAMBDA_CYCLE\n",
        "            + identity_horse_loss * LAMBDA_IDENTITY\n",
        "            + identity_zebra_loss * LAMBDA_IDENTITY\n",
        "        )\n",
        "\n",
        "        opt_gen.zero_grad()\n",
        "        G_loss.backward()\n",
        "        opt_gen.step()\n",
        "\n",
        "        if idx % 200 == 0:\n",
        "            save_image(fake_horse * 0.5 + 0.5, f\"saved_images/horse_{idx}.png\")\n",
        "            save_image(fake_zebra * 0.5 + 0.5, f\"saved_images/zebra_{idx}.png\")\n",
        "\n",
        "        loop.set_postfix(H_real=H_reals / (idx + 1), H_fake=H_fakes / (idx + 1))\n"
      ],
      "metadata": {
        "id": "Cp03xBxz02rT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(dirA, dirB, batch_size, lr, device):\n",
        "    disc_H = Discriminator(3).to(device)\n",
        "    disc_Z = Discriminator(3).to(device)\n",
        "    gen_Z = Generator(3, 3).to(device)\n",
        "    gen_H = Generator(3, 3).to(device)\n",
        "    opt_disc = optim.Adam(\n",
        "        list(disc_H.parameters()) + list(disc_Z.parameters()),\n",
        "        lr=lr,\n",
        "        betas=(0.5, 0.999),\n",
        "    )\n",
        "\n",
        "    opt_gen = optim.Adam(\n",
        "        list(gen_Z.parameters()) + list(gen_H.parameters()),\n",
        "        lr=lr,\n",
        "        betas=(0.5, 0.999),\n",
        "    )\n",
        "\n",
        "    L1 = nn.L1Loss()\n",
        "    mse = nn.MSELoss()\n",
        "\n",
        "\n",
        "    dataset = HorseZebraDataset(\n",
        "        root_horse=dirA,\n",
        "        root_zebra=dirB,\n",
        "        transform=transforms,\n",
        "    )\n",
        "    loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "\n",
        "    for epoch in range(10):\n",
        "        train_fn(\n",
        "            disc_H,\n",
        "            disc_Z,\n",
        "            gen_Z,\n",
        "            gen_H,\n",
        "            loader,\n",
        "            opt_disc,\n",
        "            opt_gen,\n",
        "            L1,\n",
        "            mse,\n",
        "            device\n",
        "        )\n"
      ],
      "metadata": {
        "id": "kzIOD4m32EUe"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "main(\"/content/dataset/trainA\", \"/content/dataset/trainB\",batch_size=1,lr=1e-5,device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fNQ1cRc2-Nt",
        "outputId": "408404f7-5a14-4107-caee-bb1a2ab585cc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1334/1334 [02:10<00:00, 10.20it/s, H_fake=0.39, H_real=0.599]\n",
            "100%|██████████| 1334/1334 [02:13<00:00,  9.97it/s, H_fake=0.373, H_real=0.61]\n",
            "100%|██████████| 1334/1334 [02:13<00:00,  9.97it/s, H_fake=0.346, H_real=0.631]\n",
            "100%|██████████| 1334/1334 [02:13<00:00,  9.96it/s, H_fake=0.33, H_real=0.643]\n",
            "100%|██████████| 1334/1334 [02:13<00:00,  9.97it/s, H_fake=0.317, H_real=0.652]\n",
            "100%|██████████| 1334/1334 [02:13<00:00,  9.96it/s, H_fake=0.313, H_real=0.659]\n",
            "100%|██████████| 1334/1334 [02:13<00:00,  9.96it/s, H_fake=0.304, H_real=0.67]\n",
            "100%|██████████| 1334/1334 [02:13<00:00,  9.97it/s, H_fake=0.301, H_real=0.677]\n",
            "100%|██████████| 1334/1334 [02:13<00:00,  9.96it/s, H_fake=0.301, H_real=0.678]\n",
            "100%|██████████| 1334/1334 [02:13<00:00,  9.98it/s, H_fake=0.295, H_real=0.689]\n"
          ]
        }
      ]
    }
  ]
}